# 8章 回帰:レコメンドの改良
前半(8.1)：映画のスコアを予測するための、よりよい手法の紹介
- 類似ユーザから予測する(8.1.1)
- 類似映画から予測する(8.1.2)
- 複数の手法を組み合わせる = 「アンサンブル学習」または「スタック学習」と呼ばれる手法 (8.1.3)

後半(8.2)：バスケット分析の紹介（"この商品を買った人はこんな商品も買っています"を実現する分析手法）
- これまでに一緒に買われた商品がどれか、という情報だけから学習する

## 8.1 推薦システムを改良する

### 8.1.1 二値行列を用いたレコメンド
興味深い教訓 : どの映画に点数を付けたかを知ることだけで、そのスコアを知らなくても、ユーザに対してかなり多くのことを知ることができる

→　ユーザが点数を付けた映画を1、点数を付けていない映画を0とする二値行列を用いるだけでも、有用な予測ができる。
- ユーザは、これまでの経験から自分が好きそうな映画を選んで観る
- ユーザは、これまで観て印象に残っている映画にレビューとして点数をつける

この二値行列を可視化すると以下になる
※スペースの都合で200×200の範囲のみ表示している

![図8-1](https://raw.githubusercontent.com/ktanizaki/dl-reading/images/1400_08_03%2B.png "図8-1")

図8-1

この二値行列を用いて映画のスコアを予測する手順は以下の2ステップになる
1. ユーザごとに、他のユーザを似ている順にランク付けする

  下表のようなイメージ。実際は「似ている度合い」を計算するために、二値行列から相関計数を計算する

  > corr_between_user1_ and_user2 = np.corrcoef(user1, user2) [0,1]

表A 二値行列のイメージ（実際は、943ユーザ × 1682映画 = 1586126個の数値データ）

|ユーザ|映画1に点数を付けたか|映画2に点数を付けたか|映画3に点数を付けたか|映画4に点数を付けたか|映画5に点数を付けたか|似ている度合い|
|:-:|:-:|:-:|:-:|:-:|:-:|:-:|
|ユーザn|1|0|1|1|0|-|
|ユーザx|1|0|1|1|0|1番目に似ている|
|ユーザy|1|0|1|1|1|2番目に似ている|
|ユーザz|1|0|0|1|1|3番目に似ている|


2. 特定のユーザと特定の映画のペアデータに対して、そのレーティングを予測する場合、ステップ1の結果を元に類似ユーザを順に見ていく

 上の例で考えると、ユーザnが映画5に何点をつけるか予測する場合、ユーザyやユーザzの点数から予測する

  書籍で紹介されているコードでは、類似度の高い順に100人のユーザを選び、そのユーザが付けた点数の平均値を予測結果とする。

  ただし、同じ100人でも、映画によって点数が付けられている数が多かったり少なかったりするため、それを考慮して予測結果を修正する必要がある

  > estimates /= (.1+br[selected].mean(0))

この方法では、映画の点数を付ける回数が多いユーザほど、予測の精度が良くなる。映画の点数を付ける回数が多い上位半分のユーザを対象にすると、25%誤差を減らすことができる。

### 8.1.2 類似映画について考える
映画を対象とした最近傍探索に基づく推薦システムを作成する。
あるユーザの映画Mに対するレーティングを予測する場合、映画Mに最も似ている映画と同じレーティングとすることができる。

1. 映画の類似行列を計算する。

 ユーザが各映画に付けた点数の行列から、映画同士の相関を計算する
 - これもnp.corrcoef関数を使って計算する

表B 行列のイメージ（実際は、943ユーザ × 1682映画 = 1586126個の数値データ）

|ユーザ|映画1の点数|映画2の点数|映画3の点数|映画4の点数|映画5の点数|
|:-:|:-:|:-:|:-:|:-:|:-:|
|ユーザx|3|0|4|2|0|
|ユーザy|4|0|1|3|2|
|ユーザz|5|0|0|2|1|


表C 相関の計算結果のイメージ ※類似結果が自分自身であることを防ぐために、対角要素は-1を設定

||映画1|映画2|映画3|映画4|映画5|
|:-:|:-:|:-:|:-:|:-:|:-:|
|映画1|-1.000e+00|5.967e-01|4.557e-01|1.498e-01|5.008e-01|
|映画2|5.967e-01|-1.000e+00|5.345e-01|2.824e-01|6.911e-01|
|映画3|4.557e-01|5.345e-01|-1.000e+00|1.928e-01|9.466e-01|
|映画4|1.498e-01|2.824e-01|1.928e-01|-1.000e+00|3.306e-01|
|映画5|5.008e-01|6.911e-01|9.466e-01|3.306e-01|-1.000e+00|

2. 類似行列を基に、ユーザと映画の各組合せについて予測する。

 上の表の例でユーザnが映画5に何点付けるかを予測したい場合、映画5と似ている映画に対して点数を付けているかを順に探して、最初に見つかった点数を映画5の点数とする

> これらの手法で交差検定を行う場合、テストを行うユーザを除いて類似行列を作成する必要があるため、時間がかかる。

### 8.1.3 複数の手法を組み合わせる
8.1.1と8.1.2の2つの手法を組み合わせて、一つの予測器を作成することができる

- 案1 : 両予測器のレーティングの平均を最終的なレーティングとする  →　両予測器の重みを0.5にする必然性はない

- 案2 : 両予測器の精度に応じて重みを考慮し、加重平均から最終的なレーティングを出す　→　この方法を採用する（アンサンブル学習）

  [最終の予測レーティング] = [(予測器1が予測したレーティング)×(予測器1の重み) ＋ (予測器2が予測したレーティング)×(予測器2の重み) + ・・・)] / [予測器1の重み + 予測器2の重み + ・・・]

アンサンブル学習は以下の特徴がある
- 各予測器を新しい特徴量として考えることができる
- 訓練データを基にその新しい特徴量の組み合わせを学習する
- 回帰以外にも適用可能
  - 例えばクラス分類で、複数の分類器を組み合わせて最終的な分類結果を出力することができる
- 得られた重みから、各予測器や分類器のどれが有効かを判断することができるので、色々なアイデアの有効性を検証するのに使える
  - 重みが大きければその予測器や分類器は有効

これまでの3つの手法を組み合わせて実際に計算すると、各重みは次の通りになる
- 第7章で用いた手法 : 約0.25
- 類似ユーザから予測する手法（8.1.1で用いた手法） : 約0.01
- 類似映画から予測する手法（8.1.2で用いた手法） : 約0.61

 →　類似映画から予測する手法は単独で用いても一番精度が良いので、重みが大きくなっている。逆に類似ユーザから予測する手法は最終結果にほとんど影響を与えていないので、使わないようにしても良いかも。

他のアイデアを追加して検証することも簡単にできる。ただし、過学習にならないように注意が必要。
- 手法の組み合わせを決めるための交差検定を行っていない。あまりに多くのことをランダムに試行すると、汎可能力が低くても、そのデータセットに適合する場合が出てくる
- データがたくさんある場合は、最終的なモデルができあがるまで手を全く付けないクリーンなデータをとっておいて、最終的にそのデータでモデルを評価すべき

## 8.2 バスケット分析
バスケット分析は、どのアイテムが一緒に購入されているか、というデータだけから推薦システムを学習する手法
- 点数が付けられているデータを入手できなくても分析できる
- 多くの場合、スコアデータより、バスケットデータ（一緒に購入されたアイテムのデータ）のほうが簡単に集められる
  - ユーザの多くはアイテムをレビューしてくれないが、何を一緒に買ったかは、買い物をすれば自然とデータが溜まる

下図のような推薦システムを作ることができる

  ![図8-2](https://raw.githubusercontent.com/ktanizaki/dl-reading/images/%E5%9B%B38-2.png "図8-2")

  図8-2

この学習手法は、一緒にグループとしてまとめることができ、その中のアイテムをレコメンドする必要がある場合は適用可能
- eメールで、追加する「受取人」を予測する
- ブラウザの閲覧履歴から、そのユーザにおすすめのwebページを推薦する
- これまでの買い物全部を一まとめにして、一回の買い物とみなして推薦することもできる
 - これはビジネスでどのようなことが求められているかに依存する

> バスケット分析で有名なのは「ビールとおむつ」の話

### 8.2.1 役立つ予測を行う
× 「この商品を買った人はこんな商品も買っています」
- システムがこの言葉通りのことを行うと、よく購入されるアイテムに騙される
- たとえば、スーパでは多くの人がパンを買うので、この言葉通りのシステムだと、パンが常に推薦される

  →　この推薦は役に立たない

○ 「この商品を買った人は、次の商品を買う傾向が統計的に平均より高い」
- パンのように他のどの商品とも一緒に買われるものは、洗剤を買った人でも買わない人でも、買う傾向はあまり変わらない

  →　役立つ推薦を行うには、一緒に買われる傾向が平均より高いかどうかや、ユーザがこれまで何を買ってきたか（ユーザの嗜好）を考慮する必要がある


### 8.2.2 スーパの買い物かごを分析する

ここではデータセットとして、ベルギーにあるスーパマーケットのトランザクションデータを利用する
- 同時に購入された商品のIDが1行ずつ並んでいる。以下に一部を掲載する。実際は全部で88162行ある。

  > 32 48 151 308 309 1080 1132 1269 1378 1379 1380 5234
    <br>39 48 1020 1039 1122 1783 2493 3765 5235 5236 5237
    <br>...

統計データは以下の通り。ほんの数回しか購入されない商品がたくさん存在する。

表8-1

|購入回数|該当する商品の数|
|:-:|:-:|
|1回|2224|
|2～3回|2438|
|4～7回|2508|
|8～15回|2251|
|16～31回|2182|
|32～63回|1940|
|64～127回|1523|
|128～511回|1225|
|512回以上|179|

バスケット分析のアルゴリズムは、アプリオリ・アルゴリズムを使用する
- 1994年に発表されたアルゴリズム
- オープンソースのバスケット分析のアルゴリズムは他にもあるが、scikit-learnやこれまで使ってきた他のパッケージにうまく統合して使えるライブラリはない
 - 書籍執筆時には無かったということだが、現在どうなのかは調べていないため不明

アプリオリ・アルゴリズムの入力と戻り値は以下。
- 入力 : ある集合（例えば「買い物かご」の中身）を多数集めたもの
- 戻り値 : よく起こる組み合わせの集合（多くの買い物で一緒に買われることが多いアイテムの組み合わせ）

アプリオリ・アルゴリズムはボトムアップ的なアプローチをとる
- 一つの要素だけから構成される最小の候補アイテムの集合を設定し、一度に要素を一つずつ追加しながら集合を大きくしていく
- 最小の支持度(アイテムが同意に購入された回数)を閾値として設定する必要がある
> 例えば minsupport = 80

- アプリオリ・アルゴリズムは、支持度の大きい（閾値を上回る）組み合わせからなるアイテム集合を見つける
 - 支持度が閾値より大きい要素から構成されるアイテム集合は、頻出アイテム集合と呼ばれる
 - アプリオリ・アルゴリズムは、頻出アイテム集合を返すものである


参考: http://www.sist.ac.jp/~kanakubo/research/data_mining.html

### 8.2.3 アソシエーション・ルール・マイニング

 バスケット分析の最終的な目標は、アソシエーションルールを見つけること
- そのため、バスケット分析はアソシエーション・ルール・マイニングとも呼ばれる
- アソシエーション・ルールは「XであるならばYである」と表現される　→　「Xを買った人はYを買う」
 - ただし、Xを買った人全員がYを買うわけではない。正確には「Xを買った人は、通常よりもYを買う傾向が高い」。
- ルールにある「条件（X）」と「結論（Y）」には複数の要素が入りうる
 - 「X1、X2、X3を買った人は、Y1、Y2、Y3を買う」という表記も可能


 頻出集合からXとYの可能な組み合わせを全て試行することで、ルールを作ることができる
 - 必要なのは意味のあるルールだけなので、作成したルールの有用性を評価する指標が必要

 → リフト値という指標がよく用いられる

> lift(X → Y) = P(Y|X) / P(Y)
- P(Y) : Yが含まれるトランザクションが全トランザクションに占める割合 = 通常の場合のYが買われる確率
- P(Y|X) :YとX両方を含むトランザクションがXを含むトランザクションに占める割合 = ルールを適用した場合にYが買われる確率

リフト値を用いることで、ベストセラーの商品だけをレコメンドする問題を防ぐことができる
- ベストセラーの商品は、P(Y)とP(Y|X)の両方とも大きくなるため、リフト値は1に近づき、ほとんど関連がないと見なされる
 - 実際には、リフト値は少なくとも10、場合によっては100ぐらいまでの値を設定する

表8-2

|条件|結果|結果の回数|条件の回数|条件と結果の回数|リフト値|
|:-:|:-:|:-:|:-:|:-:|:-:|
|1378, 1379, 1380|1269|279(0.3%)|80|57|225|
|48, 41, 976|117|1026(1.1%)|122|51|35|
|48, 41, 16011|16010|1316(1.5%)|165|159|64|

上表の各列の意味
- 結果の回数 : 結果だけに含まれる商品のトランザクション数 = Yが買われた回数
- 条件の回数 : 条件だけに含まれる商品のトランザクション数 = Xが買われた回数
- 条件と結果の回数 : 条件と結果に含まれる商品のトランザクション数 = XとYが同時に買われた回数

リフト値の求め方
- P(Y|X) = 条件と結果の回数 / 条件の回数
- P(Y) = 結果の回数 / 全トランザクション数　※実際の全トランザクション数は88162個

上表の結果から分かること
- 1269を含むトランザクションは279個で全トランザクションの0.3%でしかない
- しかし、1378, 1379, 1380を含むトランザクション80個のうち、57個は1269も含んでいる。条件確率は57/80≒71%
- よって、1378, 1379, 1380を買った人に、1269をレコメンドすることは有用
 - リフト値が大きいルールはレコメンドに有用ということ

より確かな予測をするためには、発生した回数のデータがある程度の数である必要がある
- そのためには、はじめに頻出アイテム集合を選択する必要がある
- 支持度が80であり、リフト値が5であるためには、1030個のデータセットが必要
 - なぜ1030個なのかは不明・・・
- 何百万のトランザクションを対象とすると、何千、何百万というアソシエーション・ルールが生成されるが、各ユーザによって関係あるルールは一部のみのため、実際にユーザにレコメンドされる商品の数は少なくなる

### 8.2.4 進んだバスケット分析
アプリオリよりも進んだバスケット分析のアルゴリズムが存在する
- アプリオリよりも高速に実行できるアルゴリズム（FPGrowthなど）
 - 10万個程度のトランザクションであれば、アプリオリで十分
 - もし何百万ものトランザクションを扱う場合は、より高速なアルゴリズムが必要


- ルールを作成するために、これまで行った買い物の順番を考慮する手法
 - 例えば、パーティグッズを購入した人にゴミ袋を推薦するのは理にかなっている
 - しかし、ゴミ袋を買った人にパーティーグッズを推薦するのはおかしい

これらの先進的なバスケット分析のアルゴリズムはpyminingという名前のパッケージがOSSとして提供されている
- https://github.com/bartdag/pymining からコードを取得できる
- ライセンスはNew BSD License

## 8.3 まとめ
前半(8.1)：映画のスコアを予測するための、よりよい手法の紹介
- ユーザの映画スコアを予測する予測器を改善した
- アンサンブル学習（またはスタック学習）で、異なるアイデアを組み合わせる方法を学んだ

後半(8.2)：バスケット分析の紹介（"この商品を買った人はこんな商品も買っています"を実現する分析手法）
- バスケット分析、アソシエーション・ルール・マイニングを学んだ
- 購入履歴のデータさえあれば分析できるのが利点
- アソシエーション・ルール・マイニングを行うときは、ベストセラーを推薦しないようにリフト値を考慮する必要がある
